{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRIANDO O MODELO PARA RECONHECIMENTO DE IMAGEM \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O Desafio proposto era criar um modelo de reconhecimento de imagem, onde pudesse reconhecer quais imagens eram de gatos e quais eram as de cachorros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Carregando as bibliotecas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Foram utilizadas as bibliotecas: tensorflow, keras, ImageDataGenerator, VGG16, Model, Dense e GlobalAveragePooling2D do módulo tensorflow.keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando as bibliotecas\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Definimos as configurações para o treinamento do modelo, incluindo a largura e altura das imagens (img_width e img_height), o tamanho do lote (batch_size), os diretórios de treinamento e validação (train_data_dir e validation_data_dir) e o número de épocas (epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 16\n",
    "train_data_dir = r'C:\\Users\\Nayar\\OneDrive\\Documentos\\Nayara Valevskii\\Infinity School\\Desafio Redes Neurais\\img_treino'\n",
    "validation_data_dir = r'C:\\Users\\Nayar\\OneDrive\\Documentos\\Nayara Valevskii\\Infinity School\\Desafio Redes Neurais\\img_validacao'\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O VGG16 é um modelo de rede neural convolucional (CNN) muito conhecido e eficaz, amplamente utilizado para tarefas de classificação de imagens. Nesta linha de código, estamos criando uma instância do modelo VGG16 como base para o nosso modelo de classificação de cachorros e gatos.\n",
    "\n",
    "> Weights='imagenet': Especificamos o conjunto de pesos a serem usados pelo modelo. O valor 'imagenet' indica que queremos carregar os pesos pré-treinados do modelo VGG16 treinado no conjunto de dados ImageNet. Esses pesos foram treinados em um conjunto enorme e diversificado de imagens e podem capturar características gerais úteis para tarefas de classificação de imagens.\n",
    "\n",
    "> include_top=False: Isso indica que não queremos incluir as camadas finais de classificação do VGG16, que são responsáveis por mapear as características aprendidas para as classes do conjunto de dados ImageNet original. Ao definir include_top=False, excluímos essas camadas finais e teremos a flexibilidade de adicionar nossas próprias camadas personalizadas para nossa tarefa de classificação de cachorros e gatos.\n",
    "\n",
    "> input_shape=(img_width, img_height, 3): Especificamos a forma das imagens de entrada que o modelo VGG16 espera receber. As dimensões (img_width, img_height) indicam o tamanho desejado para as imagens de entrada (150x150 pixels neste caso), e 3 representa os três canais de cor (vermelho, verde e azul - RGB). É importante fornecer imagens de entrada com a mesma forma definida aqui para garantir que o modelo funcione corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Carregar o modelo pré-treinado (VGG16) com os pesos do ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Congelamos as camadas do modelo pré-treinado definindo layer.trainable = False para cada camada no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar as camadas do modelo pré-treinado\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Adicionamos novas camadas no topo do modelo. Primeiro, aplicamos um GlobalAveragePooling2D para reduzir as dimensões da saída. Em seguida, adicionamos uma camada Dense com 512 unidades e função de ativação ReLU. Por fim, adicionamos uma camada de saída Dense com 2 unidades (uma para cada classe - cachorro e gato) e função de ativação softmax para obter as probabilidades de cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar novas camadas\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Criamos o modelo final, especificando as entradas (inputs=base_model.input) e as saídas (outputs=predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o modelo final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Compilamos o modelo usando o otimizador 'adam', a função de perda 'categorical_crossentropy' e a métrica 'accuracy' para avaliar o desempenho do modelo durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Criamos geradores de dados para o treinamento e a validação usando ImageDataGenerator. Esses geradores aplicam várias transformações nas imagens, como redimensionamento, rotação, zoom e espelhamento horizontal, para enriquecer o conjunto de dados de treinamento e evitar overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O gerador de treinamento train_generator é criado a partir do diretório de treinamento, especificando o tamanho das imagens alvo, o tamanho do lote e o modo 'categorical' para tratar as classes como variáveis categóricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O gerador de validação validation_generator é criado de forma semelhante, mas a partir do diretório de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202 images belonging to 2 classes.\n",
      "Found 207 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Criar geradores de dados para treinamento e validação\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size, class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Realizamos o ajuste fino do modelo chamando model.fit(), passando o gerador de treinamento, o número de épocas e o gerador de validação. Durante o treinamento, o modelo será ajustado para melhor se adequar ao conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 212s 17s/step - loss: 0.7534 - accuracy: 0.5495 - val_loss: 0.5062 - val_accuracy: 0.8213\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 300s 24s/step - loss: 0.4936 - accuracy: 0.7772 - val_loss: 0.3984 - val_accuracy: 0.8454\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 298s 24s/step - loss: 0.4068 - accuracy: 0.8267 - val_loss: 0.3562 - val_accuracy: 0.8261\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 348s 28s/step - loss: 0.3396 - accuracy: 0.8614 - val_loss: 0.3527 - val_accuracy: 0.8357\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 334s 27s/step - loss: 0.3016 - accuracy: 0.8713 - val_loss: 0.2570 - val_accuracy: 0.9034\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 198s 15s/step - loss: 0.2810 - accuracy: 0.8762 - val_loss: 0.2870 - val_accuracy: 0.8502\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 98s 8s/step - loss: 0.2947 - accuracy: 0.8861 - val_loss: 0.3042 - val_accuracy: 0.8502\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 99s 8s/step - loss: 0.2903 - accuracy: 0.8762 - val_loss: 0.2261 - val_accuracy: 0.8937\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 100s 8s/step - loss: 0.2566 - accuracy: 0.9059 - val_loss: 0.1915 - val_accuracy: 0.9275\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 98s 8s/step - loss: 0.2177 - accuracy: 0.9109 - val_loss: 0.1886 - val_accuracy: 0.9179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x243ef505b50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizar o ajuste fino do modelo\n",
    "model.fit(train_generator, epochs=epochs, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Após o treinamento, salvamos o modelo treinado em um arquivo chamado 'cachorro_gato_modelo_treinado.h5' usando model.save()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Salvar o modelo treinado\n",
    "model.save('cachorro_gato_modelo_treinado.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Esse código cria e treina um modelo baseado no VGG16 com camadas personalizadas para classificação de imagens de cachorro e gato. O ajuste fino é realizado para adaptar o modelo pré-treinado ao seu problema específico. Os geradores de dados são usados para fornecer lotes de imagens durante o treinamento, aplicando transformações para melhorar a diversidade dos dados.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TESTANDO O MODELO CRIADO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Primeiro, importamos as bibliotecas necessárias: tensorflow, keras, load_img e img_to_array do módulo tensorflow.keras.preprocessing.image, e numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Carregamos o modelo treinado usando keras.models.load_model()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo treinado\n",
    "model = keras.models.load_model('cachorro_gato_modelo_treinado.h5')  # Certifique-se de ter o arquivo do modelo treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Mapeamos os rótulos das classes para interpretar os resultados da previsão. Nesse caso, usamos o dicionário class_labels, onde o índice 0 corresponde a \"Cachorro\" e o índice 1 corresponde a \"Gato\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear os rótulos das classes\n",
    "class_labels = {0: 'Cachorro', 1: 'Gato'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Definimos a função fazer_previsao(imagem_path) para fazer a previsão de uma única imagem. Ela recebe o caminho da imagem como argumento.\n",
    "\n",
    "> Dentro da função, carregamos a imagem usando load_img, redimensionamos a imagem para o tamanho desejado (150x150 pixels neste caso), convertemos a imagem em um array com img_to_array, expandimos as dimensões do array para que fique com o formato correto (1, 150, 150, 3) e normalizamos os valores dos pixels dividindo por 255.0.\n",
    "\n",
    "> Em seguida, usamos o modelo treinado para fazer a previsão chamando model.predict(imagem). Isso retorna uma matriz de previsões para cada classe, onde cada valor representa a probabilidade da imagem pertencer a essa classe.\n",
    "\n",
    "> Usamos np.argmax(previsao) para obter o índice da classe com a maior probabilidade, ou seja, a classe prevista.\n",
    "\n",
    "> Com base no índice da classe prevista, mapeamos o rótulo correspondente usando o dicionário class_labels.\n",
    "\n",
    "> Retornamos o rótulo predito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para fazer previsão de uma única imagem\n",
    "def fazer_previsao(imagem_path):\n",
    "    imagem = load_img(imagem_path, target_size=(150, 150))  # Redimensionar a imagem conforme necessário\n",
    "    imagem = img_to_array(imagem)\n",
    "    imagem = np.expand_dims(imagem, axis=0)\n",
    "    imagem = imagem / 255.0  # Normalizar os valores dos pixels\n",
    "\n",
    "    # Fazer a previsão com o modelo\n",
    "    previsao = model.predict(imagem)\n",
    "    classe_predita = np.argmax(previsao)\n",
    "    rotulo_predito = class_labels[classe_predita]\n",
    "\n",
    "    return rotulo_predito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Em seguida, definimos duas variáveis imagem1 e imagem2 com os caminhos para as imagens de teste.\n",
    "\n",
    "> Chamamos a função fazer_previsao() para fazer a previsão de cada imagem.\n",
    "\n",
    "> Por fim, imprimimos os resultados das previsões no console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "A imagem1 é um(a) Cachorro\n",
      "A imagem2 é um(a) Cachorro\n"
     ]
    }
   ],
   "source": [
    "# Testar a previsão com algumas imagens de exemplo\n",
    "imagem1 = r'C:\\Users\\Nayar\\OneDrive\\Documentos\\Nayara Valevskii\\Infinity School\\Desafio Redes Neurais\\cachorro4.jpg'\n",
    "imagem2 = r'C:\\Users\\Nayar\\OneDrive\\Documentos\\Nayara Valevskii\\Infinity School\\Desafio Redes Neurais\\cachorro5.jpg'\n",
    "\n",
    "previsao1 = fazer_previsao(imagem1)\n",
    "previsao2 = fazer_previsao(imagem2)\n",
    "\n",
    "print(f'A imagem1 é um(a) {previsao1}')\n",
    "print(f'A imagem2 é um(a) {previsao2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observações Finais** : O modelo criado teve um accuracy bem positiva, mas ele ainda não deve ser usado como o modelo ideal para reconhecimento dessas imagens. O motivo é que ele foi treinado em cima de uma base de dados pequena, e com certeza ao passar outras imagens pelo modelo, pode não reconhecer corretamente, pela falta de treinamento efetivo.\n",
    "\n",
    "O intuito do desafio era apenas melhorar o código dado anteriormente pelo professor, então foram feitas modificações na base de dados para o treinamento, incluindo mais imagens na internet e mudando a biblioteca de Perceptron para Tensorflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
